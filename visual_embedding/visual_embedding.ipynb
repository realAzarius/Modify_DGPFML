{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import read_data, read_client_data\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 embedding 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Encoder specification\n",
    "        self.enc_linear_1 = nn.Linear(input_size, self.embedding_size)\n",
    "        \n",
    "        # Decoder specification\n",
    "        self.dec_linear_1 = nn.Linear(self.embedding_size, input_size)\n",
    "\n",
    "    def forward(self, images):\n",
    "        code = self.encode(images)\n",
    "        out = self.decode(code)\n",
    "        return out, code\n",
    "    \n",
    "    def encode(self, code):\n",
    "        code = self.enc_linear_1(code)\n",
    "        return code\n",
    "    \n",
    "    def decode(self, code):\n",
    "        out = F.sigmoid(self.dec_linear_1(code))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义客户端，继承自 Process 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(cid, epochs, model, emb):\n",
    "    save_name = 'C' + str(cid) + '_E' + str(epochs) + '_result'\n",
    "\n",
    "    # save embedding\n",
    "    with open(save_name+'.txt', 'a+') as emb_fp:\n",
    "        emb_fp.write(','.join(list(map(str, emb)))+'\\n')\n",
    "\n",
    "    # save model\n",
    "    model_path = os.path.join(\"saved_models\", \"cifia100\")\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    torch.save(model, os.path.join(model_path, save_name + '.pt'))\n",
    "    \n",
    "\n",
    "'''\n",
    "返回 embedding\n",
    "'''\n",
    "def train(cid, train_data, epochs, lr):\n",
    "    batch_size = 128\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = EmbModel(3072, 15)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    epochs = epochs\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    train_data_fullloader = DataLoader(train_data, batch_size=len(train_data), shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            X = X.reshape(-1, 3072)\n",
    "            out, code = model(X)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss = loss_fn(out, X)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                encoded = torch.zeros([1, 15], dtype=torch.float)\n",
    "                encoded = model.encode(next(iter(train_data_fullloader)))\n",
    "            emb = torch.mean(encoded, axis=0).numpy().tolist()\n",
    "\n",
    "            save_results(cid, epoch, model, emb)\n",
    "    \n",
    "    # return embedding\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded = torch.zeros([1, 15], dtype=torch.float)\n",
    "        encoded = model.encode(next(iter(train_data_fullloader)))\n",
    "    return torch.mean(encoded, axis = 0, keepdims = True).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 6.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(torch.sum(a, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clients = 5\n",
    "epochs = 500\n",
    "learning_rate = 0.05\n",
    "dataset = \"cifia100\"\n",
    "data = read_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tSNEVisual(save_name, input_vector):\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.manifold import TSNE\n",
    "\n",
    "        labels = []\n",
    "        col = 0\n",
    "\n",
    "        for i in range(100):\n",
    "            labels.append(col)\n",
    "            # next label\n",
    "            if (i+1) % 5 == 0:\n",
    "                col += 1\n",
    "\n",
    "        # Scaling the coordinates to [0, 1]\n",
    "        def plot_embedding(data):\n",
    "            x_min, x_max = np.min(data, 0), np.max(data, 0)\n",
    "            data = (data - x_min) / (x_max - x_min)\n",
    "            return data\n",
    "        \n",
    "        tsne = TSNE(n_components=2, init='pca', random_state=0, n_jobs=30, verbose=1, n_iter=10000)\n",
    "        X_tsne = tsne.fit_transform(input_vector)\n",
    "        aim_data = plot_embedding(X_tsne)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.subplot(111)\n",
    "        plt.scatter(aim_data[:, 0], aim_data[:, 1], c=labels)\n",
    "        plt.savefig(save_name, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current:  0\n",
      "2\n",
      "[[-617.7127075195312, -568.6993408203125, 473.13043212890625, -53.72748947143555, -8.818199157714844, 125.99597930908203, 267.3271484375, 218.1778564453125, 338.5292053222656, 384.20953369140625, -371.4195861816406, -94.0815658569336, 404.69732666015625, -118.89968872070312, 295.4736633300781]] 1\n",
      "current:  1\n",
      "2\n",
      "[[-471.06683349609375, -264.04168701171875, 339.3094177246094, -392.83099365234375, 143.5758056640625, -348.8356018066406, 364.4430847167969, -279.51678466796875, -217.2294158935547, -80.01964569091797, -283.36614990234375, -658.3558349609375, 569.9845581054688, -621.1047973632812, -270.90411376953125]] 1\n",
      "current:  2\n",
      "2\n",
      "[[108.86150360107422, 6.485332012176514, 557.6822509765625, -373.96820068359375, 336.7411193847656, -388.1986999511719, 465.2929992675781, 132.4920196533203, 48.64500045776367, 308.4232177734375, 179.9937286376953, -181.40274047851562, 95.08342742919922, 708.9345092773438, -304.086669921875]] 1\n",
      "current:  3\n",
      "2\n",
      "[[-252.37281799316406, 522.3475341796875, 502.45220947265625, -262.10699462890625, 167.1457061767578, 462.4956359863281, -300.797607421875, 293.8194580078125, 187.77500915527344, -62.128204345703125, -686.3023071289062, 137.0321044921875, 108.9669189453125, 398.109130859375, 180.7013397216797]] 1\n",
      "current:  4\n",
      "2\n",
      "[[-579.257080078125, 412.877685546875, -308.1382751464844, -71.9791259765625, 63.97781753540039, 486.5403137207031, -379.3884582519531, 32.72779846191406, 515.0978393554688, 449.2764892578125, -107.07301330566406, 56.393035888671875, -826.0674438476562, -252.54104614257812, -273.9842224121094]] 1\n"
     ]
    }
   ],
   "source": [
    "# 创建进程池\n",
    "# pool = multiprocessing.Pool(multiprocessing.cpu_count()*2)\n",
    "# result = []\n",
    "# embeddings = []\n",
    "\n",
    "for c in range(total_clients):\n",
    "    print('current: ', c)\n",
    "    cid, train_data, test_data = read_client_data(c, data, dataset)\n",
    "    res = train(c+1, train_data, epochs, learning_rate)\n",
    "    print(res, len(res))\n",
    "#     result.append(pool.apply_async(train, args=(c+1, epochs, train_data, learning_rate, )))\n",
    "\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in result:\n",
    "    embeddings.append(res.get())\n",
    "\n",
    "tSNEVisual('cifia.pdf', embeddings)\n",
    "\n",
    "\n",
    "with open('test.txt', 'a+') as emd_fp:\n",
    "    lst = [1, 2, 3]\n",
    "    emd_fp.write(','.join(list(map(str, lst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "671cbcbd291bc5ba638d356badbf7ebcda338ab821ea707ee64f21e583ba1ff9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
